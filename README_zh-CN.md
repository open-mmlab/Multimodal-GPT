# ğŸ¤– Multi-modal GPT

ä½¿ç”¨è§†è§‰å’Œè¯­è¨€æŒ‡ä»¤è®­ç»ƒä¸€ä¸ªå¤šæ¨¡æ€èŠå¤©æœºå™¨äººï¼

åŸºäºå¼€æºå¤šæ¨¡æ€æ¨¡å‹ [OpenFlamingo](https://github.com/mlfoundations/open_flamingo)ï¼Œæˆ‘ä»¬ä½¿ç”¨å…¬å¼€æ•°æ®é›†åˆ›å»ºäº†å„ç§**è§†è§‰æŒ‡ä»¤**æ•°æ®ï¼ŒåŒ…æ‹¬è§†è§‰é—®ç­”ã€å›¾åƒå­—å¹•ã€è§†è§‰æ¨ç†ã€æ–‡æœ¬ OCR å’Œè§†è§‰å¯¹è¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨ä»…åŒ…å«**è¯­è¨€æŒ‡ä»¤**æ•°æ®çš„è¯­è¨€æ¨¡å‹ç»„ä»¶è¿›è¡Œäº†è®­ç»ƒã€‚

è§†è§‰å’Œè¯­è¨€æŒ‡ä»¤çš„**è”åˆè®­ç»ƒ**æœ‰æ•ˆæé«˜äº†æ¨¡å‹çš„æ€§èƒ½ï¼æ›´å¤šç»†èŠ‚è¯·å‚é˜…æˆ‘ä»¬çš„[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2305.04790)ã€‚

æ¬¢è¿åŠ å…¥æˆ‘ä»¬ï¼

</div>

<div align="center">

[English](README.md) | ç®€ä½“ä¸­æ–‡

</div>

<div align="center">
  <a href="https://openmmlab.medium.com/" style="text-decoration:none;">
    <img src="https://user-images.githubusercontent.com/25839884/219255827-67c1a27f-f8c5-46a9-811d-5e57448c61d1.png" width="3%" alt="" /></a>
  <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
  <a href="https://discord.com/channels/1037617289144569886/1046608014234370059" style="text-decoration:none;">
    <img src="https://user-images.githubusercontent.com/25839884/218347213-c080267f-cbb6-443e-8532-8e1ed9a58ea9.png" width="3%" alt="" /></a>
  <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
  <a href="https://twitter.com/OpenMMLab" style="text-decoration:none;">
    <img src="https://user-images.githubusercontent.com/25839884/218346637-d30c8a0f-3eba-4699-8131-512fb06d46db.png" width="3%" alt="" /></a>
  <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
  <a href="https://www.youtube.com/openmmlab" style="text-decoration:none;">
    <img src="https://user-images.githubusercontent.com/25839884/218346691-ceb2116a-465a-40af-8424-9f30d2348ca9.png" width="3%" alt="" /></a>
  <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
  <a href="https://space.bilibili.com/1293512903" style="text-decoration:none;">
    <img src="https://user-images.githubusercontent.com/25839884/219026751-d7d14cce-a7c9-4e82-9942-8375fca65b99.png" width="3%" alt="" /></a>
  <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
  <a href="https://www.zhihu.com/people/openmmlab" style="text-decoration:none;">
    <img src="https://user-images.githubusercontent.com/25839884/219026120-ba71e48b-6e94-4bd4-b4e9-b7d175b5e362.png" width="3%" alt="" /></a>
</div>

## ç‰¹æ€§

- æ”¯æŒå„ç§è§†è§‰å’Œè¯­è¨€æŒ‡ä»¤æ•°æ®
- ä½¿ç”¨ LoRA è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒ
- åŒæ—¶è°ƒæ•´è§†è§‰å’Œè¯­è¨€ï¼Œç›¸äº’è¡¥å……

## å®‰è£…

åœ¨ä¸€ä¸ªå·²æœ‰ç¯å¢ƒä¸­å®‰è£…ä¾èµ–åŒ…ï¼Œè¿è¡Œä»¥ä¸‹æŒ‡ä»¤

```bash
git clone https://github.com/open-mmlab/Multimodal-GPT.git
cd Multimodal-GPT
pip install -r requirements.txt
pip install -v -e .
```

æˆ–è€…åˆ›å»ºä¸€ä¸ªæ–°çš„ conda ç¯å¢ƒ

```bash
conda env create -f environment.yml
```

## Demo

1. ä¸‹è½½é¢„è®­ç»ƒæƒé‡

    ä½¿ç”¨[è¿™ä¸ªè„šæœ¬](https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/convert_llama_weights_to_hf.py)æŠŠ LLaMA æƒé‡è½¬æ¢æˆ HuggingFace æ ¼å¼ã€‚

    ä» [openflamingo/OpenFlamingo-9B](https://huggingface.co/openflamingo/OpenFlamingo-9B) ä¸‹è½½ OpenFlamingo é¢„è®­ç»ƒæ¨¡å‹ã€‚

    ä»[è¿™ä¸ªé“¾æ¥](https://download.openmmlab.com/mmgpt/v0/mmgpt-lora-v0-release.pt) ä¸‹è½½æˆ‘ä»¬çš„ LoRA æƒé‡ã€‚

    ç„¶åæŠŠæ‰€æœ‰æ¨¡å‹æƒé‡æ”¾åˆ° `checkpoints` æ–‡ä»¶å¤¹ä¸‹ï¼Œç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

    ```
    checkpoints
    â”œâ”€â”€ llama-7b_hf
    â”‚   â”œâ”€â”€ config.json
    â”‚   â”œâ”€â”€ pytorch_model-00001-of-00002.bin
    â”‚   â”œâ”€â”€ ......
    â”‚   â””â”€â”€ tokenizer.model
    â”œâ”€â”€ OpenFlamingo-9B
    â”‚   â””â”€â”€checkpoint.pt
    â”œâ”€â”€mmgpt-lora-v0-release.pt

2. å¯åŠ¨ gradio demo

    ```bash
    python app.py
    ```

## ç¤ºä¾‹

### èœå•ï¼š
![image4](https://user-images.githubusercontent.com/12907710/234554562-8f3be88f-d563-47ba-97d9-ade8d47c46b0.png)

### æ—…è¡Œè®¡åˆ’ï¼š
![image3](https://user-images.githubusercontent.com/12907710/234523464-80c4e3f0-f99f-4498-96ef-dc43ef89c64b.png)

### ç”µå½±ï¼š
![image2](https://user-images.githubusercontent.com/12907710/234523468-e11905a6-491f-4b87-934f-90da7d14d1c3.png)

### åäººï¼š
![image](https://user-images.githubusercontent.com/12907710/234523475-fd91f979-a344-4228-813f-6b55a1bc250f.png)


## å¾®è°ƒ Fine-tuning

### å‡†å¤‡æ•°æ®é›†

1. [A-OKVQA](https://allenai.org/project/a-okvqa/home)

    ä»[è¿™ä¸ªé“¾æ¥](https://prior-datasets.s3.us-east-2.amazonaws.com/aokvqa/aokvqa_v1p0.tar.gz)ä¸‹è½½æ ‡æ³¨ï¼Œè§£å‹åˆ° `data/aokvqa/annotations` è·¯å¾„ä¸‹ã€‚

    åŒæ—¶è¿˜éœ€è¦ coco æ•°æ®é›†çš„å›¾åƒï¼Œå¯ä»¥ä»[è¿™é‡Œ](https://cocodataset.org/#home)ä¸‹è½½ã€‚

2. [COCO Caption](https://cs.stanford.edu/people/karpathy/deepimagesent/)

    ä»[è¿™ä¸ªé“¾æ¥](https://cs.stanford.edu/people/karpathy/deepimagesent/coco.zip)ï¼Œè§£å‹åˆ° `data/coco` è·¯å¾„ä¸‹ã€‚

    åŒæ—¶è¿˜éœ€è¦ coco æ•°æ®é›†çš„å›¾åƒï¼Œå¯ä»¥ä»[è¿™é‡Œ](https://cocodataset.org/#home)ä¸‹è½½ã€‚

3. [OCR VQA](https://ocr-vqa.github.io/)

    ä» [è¿™ä¸ªé“¾æ¥](https://drive.google.com/drive/folders/1_GYPY5UkUy7HIcR0zq3ZCFgeZN7BAfm_?usp=sharing) ä¸‹è½½æ•°æ®é›†ï¼Œæ”¾åˆ° `data/OCR_VQA/` è·¯å¾„ä¸‹ã€‚

4. [LlaVA](https://llava-vl.github.io/)

    ä» [liuhaotian/LLaVA-Instruct-150K](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K) ä¸‹è½½æ•°æ®é›†ï¼Œæ”¾åˆ° `data/llava/` è·¯å¾„ä¸‹ã€‚

    åŒæ—¶è¿˜éœ€è¦ coco æ•°æ®é›†çš„å›¾åƒï¼Œå¯ä»¥ä»[è¿™é‡Œ](https://cocodataset.org/#home)ä¸‹è½½ã€‚

5. [Mini-GPT4](https://minigpt-4.github.io/)

    ä» [Vision-CAIR/cc_sbu_align](https://huggingface.co/datasets/Vision-CAIR/cc_sbu_align) ä¸‹è½½æ•°æ®é›†ï¼Œæ”¾åˆ° `data/cc_sbu_align/` è·¯å¾„ä¸‹ã€‚

6. [Dolly 15k](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html)

    ä» [databricks/databricks-dolly-15k](https://huggingface.co/datasets/databricks/databricks-dolly-15k) ä¸‹è½½æ•°æ®é›†ï¼Œæ”¾åˆ° `data/dolly/databricks-dolly-15k.jsonl` è·¯å¾„ä¸‹ã€‚

7. [Alpaca GPT4](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM)

    ä»[è¿™ä¸ªé“¾æ¥](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/raw/main/data/alpaca_gpt4_data.json) ä¸‹è½½æ•°æ®é›†ï¼Œæ”¾åˆ° `data/alpaca_gpt4/alpaca_gpt4_data.json` è·¯å¾„ä¸‹ã€‚

ä½ ä¹Ÿå¯ä»¥åœ¨ [configs/dataset_config.py](configs/dataset_config.py) æ–‡ä»¶ä¸­è‡ªå®šä¹‰æ•°æ®é›†è·¯å¾„ã€‚


## å¼€å¯è®­ç»ƒ

```bash
torchrun --nproc_per_node=8 mmgpt/train/instruction_finetune.py \
  --lm_path checkpoints/llama-7b_hf \
  --tokenizer_path checkpoints/llama-7b_hf \
  --pretrained_path checkpoints/OpenFlamingo-9B/checkpoint.pt \
  --run_name train-my-gpt4 \
  --learning_rate 1e-5 \
  --lr_scheduler cosine \
  --batch_size 1 \ 
  --tuning_config configs/lora_config.py \
  --dataset_config configs/dataset_config.py \
  --report_to_wandb
```


## è‡´è°¢

- [OpenFlamingo](https://github.com/mlfoundations/open_flamingo)
- [LAVIS](https://github.com/salesforce/LAVIS)
- [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca)
- [MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)
- [LLaVA](https://github.com/haotian-liu/LLaVA/tree/main)
- [Instruction Tuning with GPT-4](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM)

å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹ä½ çš„ç ”ç©¶å’Œåº”ç”¨æœ‰å¸®åŠ©ï¼Œè¯·ç”¨ä»¥ä¸‹ BibTeX è¿›è¡Œå¼•ç”¨

```bibtex
@misc{gong2023multimodalgpt,
      title={MultiModal-GPT: A Vision and Language Model for Dialogue with Humans}, 
      author={Tao Gong and Chengqi Lyu and Shilong Zhang and Yudong Wang and Miao Zheng and Qian Zhao and Kuikun Liu and Wenwei Zhang and Ping Luo and Kai Chen},
      year={2023},
      eprint={2305.04790},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```
